#!/bin/bash
SDIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" > /dev/null 2>&1 && pwd)"
[[ ! -f $SDIR/jh_config ]] && >&2 echo "All wrapper scripts should be placed in the same directory!" && exit 1
source $SDIR/jh_config
# Purpose:
# Wrapper Script to start a wlm job with JupyterHub batchspawner
# The output should ONLY contain the ccs job id so that the batchspawner can extract it!!! (e.g. 5699532)
# if JupyterHub (batchspawner) calls this script, following environment variables will pass it: JUPYTERHUB_USER (Username), JUPYTERHUB_API_TOKEN, ...
# This script copies a singularity container for each new user in $home_dir directory

# Following procedure:
# 1. Writes from STDIN to $WRAP_TMP_JOB
# 2. Check whether a user is new and create an empty file if so 
# 3. calling the workload manager command to start a batch job with $WRAP_TMP_JOB
# 4. The output of the workload manager call should be the unique job id so that the JupyterHub can control the job (show job status, kill job, ...)
# 5. creating job directory with job specific information (start date/time, compute node hostname, username) and create a home directory if the user is new
# 6. And now it's time for $WRAP_TMP_JOB 

### CHECK WHETHER CLUSTER IS IN MAINTENANCE MODE
if [[ $is_cluster_in_maintenance == true ]]; then
	if [[ ! $JUPYTERHUB_USER == $maintenance_only_user ]]; then
		>&2 echo "The HPC cluster is currently in maintenance mode!"
		exit 1	
	else
		create_log_entry "WARNING" "Maintenance user $JUPYTERHUB_USER ($maintenance_only_user) started a job..."
	fi
fi

#### TEMPLATE BATCH SCRIPT
input_=$(< /dev/stdin)
if $creating_user_homes; then
	WRAP_TMP_JOB=$(mktemp --tmpdir=$home_dir/ --suffix=.$JUPYTERHUB_USER)
else
	WRAP_TMP_JOB=$(mktemp --tmpdir=$scratch_dir/ --suffix=.$JUPYTERHUB_USER)
fi
### READING FROM STDIN AND WRITE IT TO $WRAP_TMP_JOB
echo "$input_" > $WRAP_TMP_JOB

# This overlay will be used as a persitent overlay for the user. All changes affected by the user will be stored in the overlay 
# The default overlay size can be changed in the configuration file jh_config and will be applied when a new user register
function create_empty_singularity_overlay () {

    eval $create_overlay_cmd
    eval $create_ext_overlay_cmd
	create_log_entry "INFO" "[START] Empty singularity overlay with ext3 filesystem for user $JUPYTERHUB_USER created"
}

function check_new_user () {

	if $creating_user_homes; then
		if [[ ! -d $home_dir/$JUPYTERHUB_USER ]]; then
			touch $home_dir/.$JUPYTERHUB_USER.is_new
		fi
	fi
}

function create_user_home () {

	if $creating_user_homes; then
		if [[ ! -d $home_dir/$JUPYTERHUB_USER ]]; then
			create_log_entry "INFO" "[START] User $JUPYTERHUB_USER seems to be new.. Creating home and notebook directory"
			# create user and log directory
			mkdir -p $user_log_directory
			# create singularity overlay for user so that user changes are permanent
			if $use_singularity; then
				create_empty_singularity_overlay $home_dir/$JUPYTERHUB_USER/overlay.img
			fi
			# move previousley created job files to the new job directory
			create_log_entry "INFO" "[START] Home and notebook directory for user $JUPYTERHUB_USER created"
		else
			# user is already known (using existing notebook directory and singularity container...)
			[[ ! -d $user_log_directory ]] && mkdir $user_log_directory
			[[ -f $user_log_directory/lastlog ]] && rm $user_log_directory/lastlog
			create_log_entry "INFO" "[START] User $JUPYTERHUB_USER is already known... Using existing notebook directory and singularity overlay"
		fi
	else
		create_log_entry "DEBUG" "Not creating a user home directory for user $JUPYTERHUB_USER"
	fi

	create_log_entry "DEBUG" "Checking job in 15 seconds..."
	sleep 15
	check_started_job
}

### CHECK PREVIOUSLY STARTED JOB. SOMETIMES THE WORKLOAD MANAGER IS BR0KEN 
function check_started_job () {

	# Checking job state after 15 seconds
	create_log_entry "DEBUG" "Now checking job state!"
    cmd_job_state=$(sed "s/$JOBID/$JOBID_OUTPUT")
    eval $cmd_job_state
	# if the job state is something specified in cluster_job_is_planned
	if [[ ${cluster_job_is_planned[@]} =~ ${job_state} ]]; then

		create_log_entry "ERROR" "Job state for job $JOBID_OUTPUT changed to planned! Kill the job.."
		>&2 echo "It seems your requested resources are currently not available. Please start a notebook server with less resources or try again later."
		cmd_kill_job+=("$JOBID_OUTPUT")
		${cmd_kill_job[@]}
		exit 1
	elif [[ ${cluster_job_is_stopped[@]} =~ ${job_state} ]]; then
		create_log_entry "ERROR" "[START] The notebook job $JOBID_OUTPUT is lost after 15 seconds"
		>&2 echo "Hmm... Something went wrong. Please ask the system administrator!"
		cmd_kill_job+=("$JOBID_OUTPUT")
		${cmd_kill_job[@]}
		exit 1
	else
		create_log_entry "DEBUG" "Job status for user $JUPYTERHUB_USER with ID $JOBID_OUTPUT checked. Everything seems fine until here"
	fi
}

# Start job 
function run_wlm_job () {

    # mark the job file as executable
	chmod 700 $WRAP_TMP_JOB

	if $creating_user_homes; then
		[[ ! -d $user_log_directory ]] && mkdir $user_log_directory
	fi

	if $enable_debug_mode; then
		cmd_run_job_debug+=("$WRAP_TMP_JOB")
		JOBID_OUTPUT=$(${cmd_run_job_debug[@]} | ${cmd_run_job_filter[@]})
	else
		cmd_run_job+=("$WRAP_TMP_JOB")
		JOBID_OUTPUT=$(${cmd_run_job[@]} | ${cmd_run_job_filter[@]})
	fi

	# This error code is OpenCCS specific
	if [[ $? == 105 ]]; then
		>&2 echo "It seems no job can be started. Maybe the cluster is in maintenance mode?"
		create_log_entry "ERROR" "[START] It seems no job can be started. Maybe the cluster is in maintenance mode?"
		exit 1
	fi

	create_log_entry "DEBUG" "[Workload Manager] Output: ${JOBID_OUTPUT}"

	# write job id to output -> Used by the JupyterHub to control the job
	# After output, the JupyterHub Server extracts the Job ID with the method: parse_job_id . See class CustomHPCSpawner
	JOBID_OUTPUT=$(echo $JOBID_OUTPUT | grep -Po "\\d+")

    if [[ ! $? -eq 0 ]]; then
        create_log_entry "ERROR" "Cannot filter a digit from job allocation output."
    fi

	# check whether output is zero 0
	if [[ "$JOBID_OUTPUT" -eq "0" ]]; then
		create_log_entry "ERROR" "JOBID_OUTPUT is zero??? Kill the job."
		>&2 echo "Cannot extract Job ID. Please try again."
        sleep 5
        check_started_job
	fi

	echo $JOBID_OUTPUT
	create_log_entry "INFO" "[START] Running notebook job for user $JUPYTERHUB_USER with ID $JOBID_OUTPUT"
}

### START FUNCTIONS
check_new_user
run_wlm_job
create_user_home
